APPRENTICE
This lab has an unprotected admin panel.

Solve the lab by deleting the user carlos.

Para fazer isso, testaremos outras possíveis urls de acesso a páginas:

https://0a8800f20438126a80d8b7cd001b0071.web-security-academy.net/login (padrão)
https://0a8800f20438126a80d8b7cd001b0071.web-security-academy.net/admin (mudei)
Em vez de tentar diversas vezes, como uma força bruta, tem um jeito melhor:

https://0a8800f20438126a80d8b7cd001b0071.web-security-academy.net/robots.txt

Basicamente quando temos uma aplicação web, podemos esconder algumas páginas, evitando que o usuário tenha acesso a aquela página e conteúdo.
O robots.txt vai nos apresentar essas páginas, que não apareceriam por sí só.

E achamos isso:

User-agent: *
Disallow: /administrator-panel

Depois só concluir o proposito do pentest (Apresentar a vulnerabilidade de acesso a página de admin sem ser admin.) e apagar o usuário 

https://owasp.org/Top10/A01_2021-Broken_Access_Control/

Este arquivo fica hospedado na raiz do site e apresenta instruções aos robôs das ferramentas de busca, como por exemplo o Google, Bing e Yahoo.
Portanto, por meio dele é possível indicar quais diretórios que não devem ser rastreados e arquivos que não devem ser indexados, POIS:

Os robôs das ferramentas de busca são programados para vasculhar toda a web em busca de novas páginas ou atualizações para indexar elas nos resultados de busca.

E caso a gente não queira que os robôs rastreiem determinados recursos de nossas aplicações? Aí sim que nesse caso entra em ação o arquivo robots.txt visto.
